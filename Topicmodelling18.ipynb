{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJSRep/NLP/blob/main/Topicmodelling18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU1Yq-koKnr0"
      },
      "outputs": [],
      "source": [
        "# INSTALL\n",
        "!pip install bertopic --upgrade bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Qeukg3Dw7kF"
      },
      "outputs": [],
      "source": [
        "# IMPORT\n",
        "import pandas as pd # pandas data frame\n",
        "import re # regular expressions\n",
        "import os # operating system\n",
        "import json # json!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YV_5Yl2PrFR",
        "outputId": "00ece19c-2afa-4ab3-bc48-a99d540fcbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# MOUNT\n",
        "from google.colab import drive # change for a server location in PROD\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VssgC921Pv1I"
      },
      "outputs": [],
      "source": [
        "# CHANGE DIR\n",
        "os.chdir('/content/gdrive/MyDrive/Models')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp5WHyI1Pvr8"
      },
      "outputs": [],
      "source": [
        "# CHECKS\n",
        "#print (os.getcwd())\n",
        "#print(os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwV4T-F0JCsu",
        "outputId": "84c2bfdd-a284-4f90-9fd7-878239dbc2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# PREPROCESSING - this step is not strictly required with BERTopic unless we want to use a custom stop words library\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords list if necessary\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define the stop words to remove\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('SA_20181206.csv')\n",
        "\n",
        "# Remove stopwords from the text column\n",
        "data['Scientific_Abstract'] = data['Scientific_Abstract'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "data.to_csv('SA_20181206_without_stopwords.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O13fJ2RNgiKs"
      },
      "outputs": [],
      "source": [
        "from random import seed\n",
        "# TRAIN/FIT\n",
        "\n",
        "# Import libraries\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from umap import UMAP\n",
        "\n",
        "# Load data\n",
        "abstracts = pd.read_csv (\"SA_20181206_without_stopwords.csv\")\n",
        "\n",
        "# Extract abstracts\n",
        "abstracts = abstracts[\"Scientific_Abstract\"].tolist()\n",
        "\n",
        "# Convert data to strings\n",
        "abstracts = [str(doc) for doc in abstracts]\n",
        "\n",
        "# Vectorizer\n",
        "# need more I/O for ngram_range 1,3\n",
        "vectorizer_model = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
        "\n",
        "# Embedding\n",
        "# embedding_model = sentence_model (\"all-MiniLM-L6-v2\") # use default\n",
        "# The default embedding model for SentenceTransformer in BERTopic is all-MiniLM-L6-v2 for English documents and paraphrase-multilingual-MiniLM-L12-v2 for multilingual documents.\n",
        "# These models are both pre-trained transformer-based models that are specifically designed for sentence embedding tasks.\n",
        "# They are able to capture semantic relationships between sentences, which makes them well-suited for topic modeling.\n",
        "\n",
        "# Set the random seed to a fixed value to get reproducible results\n",
        "umap_model = UMAP(random_state=42)\n",
        "\n",
        "# Dimensionality Reduction example\n",
        "# umap = UMAP(n_neighbors=15,\n",
        "#             n_components=5,\n",
        "#             min_dist=0.0,\n",
        "#             metric='cosine',\n",
        "#             low_memory=False,\n",
        "#             random_state=1337)\n",
        "# model = BERTopic(language=\"multilingual\", umap_model=umap)\n",
        "# topics, probs = model.fit_transform(content)\n",
        "\n",
        "\n",
        "# Create a BERTopic instance\n",
        "topic_model = BERTopic(\n",
        "    umap_model=umap_model,\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    language=\"english\")\n",
        "\n",
        "# Fit the BERTopic model - fit_transform is a single step to fit and predict\n",
        "topics, probs = topic_model.fit_transform(abstracts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNrd0a537vUF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7LL5GOgiE0",
        "outputId": "f7b9168d-3975-4b29-a28a-4a83921d46e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-12-12 19:06:54,308 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
          ]
        }
      ],
      "source": [
        "# SAVE\n",
        "from bertopic import BERTopic\n",
        "topic_model.save(\"Screening_Model_v16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPx5bTY2gh8E"
      },
      "outputs": [],
      "source": [
        "# RAW TOPICS (TOP 30)\n",
        "topic_model.get_topic_info().head(30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GET TOP 10 WORDS FOR TOPIC 0\n",
        "topic_model.get_topic(0)[:10]"
      ],
      "metadata": {
        "id": "5T47HrNjMJP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgfi_1n_ghwE"
      },
      "outputs": [],
      "source": [
        "# BAR CHARTS OF TOP 20 TOPICS (10 WORDS)\n",
        "topic_model.visualize_barchart (width=280, height=330, top_n_topics=30, n_words=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC LABELS\n",
        "topic_labels = topic_model.generate_topic_labels(nr_words=3,\n",
        "                                                 topic_prefix=True,\n",
        "                                                 word_length=10,\n",
        "                                                 separator=\", \")\n",
        "\n",
        "topic_model.set_topic_labels(topic_labels)\n",
        "\n",
        "topic_model.set_topic_labels({0: \"0 - Women & Pregnancy\", 1: \"1 - Asthma & COPD\"})\n",
        "\n",
        "# Re-run Barchart visualisation\n",
        "topic_model.visualize_barchart (width=280, height=330, top_n_topics=30, n_words=10, custom_labels=True)"
      ],
      "metadata": {
        "id": "onW1Iy7GOrhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVVFTSyfghjx"
      },
      "outputs": [],
      "source": [
        "#HEATMAP (20 CLUSTERS)\n",
        "topic_model.visualize_heatmap(n_clusters=20, custom_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJGQrFFIq8Vo"
      },
      "outputs": [],
      "source": [
        "# DOCUMENTS AND TOPICS\n",
        "topic_model.visualize_documents(abstracts, topics=list(range(30)),custom_labels=True, height=600)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HIERARCHICAL CLUSTERING\n",
        "topic_model.visualize_hierarchy(custom_labels=True)"
      ],
      "metadata": {
        "id": "rlhKOQ1LLxMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INTERTOPIC DISTANCE MAP\n",
        "topic_model.visualize_topics(custom_labels=True)"
      ],
      "metadata": {
        "id": "GIWSbWw_YjzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IUNJeV4Jn4g"
      },
      "outputs": [],
      "source": [
        "# PROJECTS, TOPICS, PROBABILITY (EXCLUDE -1 UNKNOWN OUTLIERS)\n",
        "\n",
        "# Combine the topic IDs, topic probabilities, and the desired column from your source data\n",
        "abstract_data = pd.read_csv (\"SA_20181206_without_stopwords.csv\")\n",
        "\n",
        "# Extract the ProjectID column\n",
        "ProjectID = abstract_data[\"ProjectID\"]\n",
        "\n",
        "topic_df = pd.DataFrame({\n",
        "\"ProjectID\": abstract_data[\"ProjectID\"],\n",
        "\"Topic_ID\": topics,\n",
        "\"Topic_Prob\": probs,\n",
        "})\n",
        "filtered_df = topic_df[topic_df['Topic_ID'] != -1]\n",
        "print (filtered_df.sample(30))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROJECTS, TOPICS, PROBABILITY (FOR TOPIC 0 - Women & Pregnancy)\n",
        "\n",
        "# Combine the topic IDs, topic probabilities, and the desired column from your source data\n",
        "abstract_data = pd.read_csv (\"SA_20181206_without_stopwords.csv\")\n",
        "\n",
        "# Extract the ProjectID column\n",
        "ProjectID = abstract_data[\"ProjectID\"]\n",
        "\n",
        "topic_df = pd.DataFrame({\n",
        "\"ProjectID\": abstract_data[\"ProjectID\"],\n",
        "\"Topic_ID\": topics,\n",
        "\"Topic_Prob\": probs,\n",
        "\"Document\": abstracts\n",
        "})\n",
        "filtered_df = topic_df[topic_df['Topic_ID'] == 0]\n",
        "print (filtered_df.sample(30))"
      ],
      "metadata": {
        "id": "Ci7jH8K4SMZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO4apnzHuHzc"
      },
      "outputs": [],
      "source": [
        "# DOCS PER TOPIC\n",
        "T = topic_model.get_document_info(abstracts)\n",
        "docs_per_topics = T.groupby([\"Topic\"]).apply(lambda x: x.index).to_dict()\n",
        "print(docs_per_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "68rQKPg6QlJz"
      },
      "outputs": [],
      "source": [
        "#LOAD\n",
        "#=====\n",
        "from bertopic import BERTopic\n",
        "topic_model = BERTopic.load(\"Screening_Model_v16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24z2iK9sQ6p6",
        "outputId": "8799f839-982a-414e-c0f9-127dd2ad4eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] [0.82899109] [\"BackgroundGood maternal & paternal health before and at conception can shape a child's future life course. This raises the importance of pre pregnancy care for screening, prevention & management of risk factors that affect pregnancy outcomes & the future health of families. There is little information about the provision of pre pregnancy care in England. Better understanding of the bio-psychosocial, cultural and economic factors affecting access to pre pregnancy care is needed if services are to be improved and more pregnancies planned. Only about 50% of pregnancies are planned. Holistic study of the complexity of health care before and between pregnancies is needed to identify interventions that are effective & acceptable to women & men, and the key contextual factors that enable health gain.AimsThe overall aim of the study is to provide high quality evidence regarding the implementation & public health impact of pre pregnancy health & care for women & men in England in order to inform future policy and practice.  The objectives are to:  - Examine literature & analyse datasets to establish evidence, guidelines & factors relating to pre pregnancy care in England.   - Holistically review current provision of pre pregnancy care in England and the impact for women & men across the lifespan.  - Assess knowledge, attitudes and behaviours of men & women of childbearing age regarding planning pregnancy & pre pregnancy care, using quantitative and qualitative methods. -  Synthesise the evidence obtained to inform policy and formulate a strategy to improve pregnancy care in EnglandPlan of InvestigationWe will use mixed methodology to explore pre pregnancy health & care in England.  We will review the literature on pre pregnancy issues, policy and care guidelines; address key questions by analysing data from two large population based studies; map service settings and information sources for pre pregnancy care in England using the World Wide Web and send questionnaires to targeted health professionals and community health workers in services providing pre pregnancy care.  Knowledge, attitudes and behaviour regarding pre pregnancy issues will be explored through a large questionnaire survey of men & women attending antenatal and infertility services, and detailed insight will be gained through in depth interviews with respondents who have, and have not, invested in pre pregnancy care.Potential ImpactThe findings of this study are expected to have an impact on development of policy in this area by laying out the evidence base, mapping the provision of services and settings for pre pregnancy care and synthesising this information with primary research findings (from quantitative and qualitative enquiry of defined subpopulations of women and men) to formulate a strategy to improve provision, uptake and impact of pre-pregnancy care in England.  In addition these findings will lead to an 'evidence-based' list of priority questions for future research.\", 'nan']\n"
          ]
        }
      ],
      "source": [
        "# PREDICT\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load data\n",
        "new_abstract = pd.read_csv (\"SA_20110401_Example_2.csv\")\n",
        "\n",
        "# Extract abstracts\n",
        "new_abstract = new_abstract[\"Scientific_Abstract\"].tolist()\n",
        "\n",
        "# Convert data to strings\n",
        "new_abstract = [str(doc) for doc in new_abstract]\n",
        "\n",
        "# Predict topics for the new document\n",
        "predicted_topics, predicted_probs = topic_model.transform([new_abstract])\n",
        "\n",
        "# Print the topics for the new document\n",
        "print(predicted_topics, predicted_probs, new_abstract)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nrJ_3_sYCJj",
        "outputId": "3198fbe4-4a1a-4515-853f-d56274a258a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([0, 40], array([0.68483457, 0.58930002]))\n"
          ]
        }
      ],
      "source": [
        "# Get the possible topics and their probabilities\n",
        "Topic_Predictions = predicted_topics, probabilities = topic_model.transform(new_abstract)\n",
        "print (Topic_Predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qXd8PuFai2R",
        "outputId": "2776f882-5b7d-46e4-9d66-d3b5c59954e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most likely topic: 0\n",
            "Probability: 0.6848345749879021\n"
          ]
        }
      ],
      "source": [
        "# Get the most likely topic and its probability\n",
        "predicted_topic = predicted_topics[probabilities.argmax()]\n",
        "probability = probabilities[probabilities.argmax()]\n",
        "\n",
        "# Print the most likely prediction and its probability\n",
        "print(\"Most likely topic:\", predicted_topic)\n",
        "print(\"Probability:\", probability)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OPTIONAL PARAMETER EXAMPLES\n",
        "\n",
        "#VECTORIZE\n",
        "#=========\n",
        "# vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
        "# umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
        "# hdbscan_model = HDBSCAN(min_cluster_size=20, min_samples=2, metric='euclidean', cluster_selection_method='eom')\n",
        "\n",
        "# #EMBEDDINGS\n",
        "# sentence_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
        "# #TO DO: might want to try all-MiniLM-L6-v2 or paraphrase-multilingual-mpnet-base-v2\n",
        "# embeddings = sentence_model.encode(documents)\n",
        "\n",
        "# #TRAIN\n",
        "# topic_model = BERTopic(\n",
        "#     vectorizer_model=vectorizer_model,\n",
        "#     embedding_model=sentence_model,\n",
        "#     # umap_model=umap_model,\n",
        "#     # hdbscan_model=hdbscan_model,\n",
        "#     language='english', calculate_probabilities=True,\n",
        "#     verbose=True\n",
        "# )"
      ],
      "metadata": {
        "id": "kabDU7LmhyXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP4SlDqTqnLQhIojNcUYEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}